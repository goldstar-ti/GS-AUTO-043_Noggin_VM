[postgresql]
host = localhost
port = 5432
database = noggin_db
user = noggin_app
password = GoodKingCoat16
schema = noggin_schema
pool_min_connections = 2
pool_max_connections = 10

[paths]
#/mnt/data --> 1TB volume
base_log_path = /mnt/data/noggin/log
base_output_path = /mnt/data/noggin/output
error_folder_path = /mnt/data/noggin/etl/input/error
input_folder_path = /mnt/data/noggin/etl/input/pending
processed_folder_path = /mnt/data/noggin/etl/input/processed

# Hash lookup sync paths (script auto-detects these from its location; can be overridden here)
# hash_sync_pending_path = /home/noggin_admin/scripts/etl/hash_sync/pending
# hash_sync_processed_path = /home/noggin_admin/scripts/etl/hash_sync/processed
# hash_sync_error_path = /home/noggin_admin/scripts/etl/hash_sync/error

[api]
base_url = https://services.apse2.elasticnoggin.com
media_service_url = https://services.apse2.elasticnoggin.com/mediaservice
namespace = 6649a25a06337e51a87b77a7d83e58f522795452456649b8e019574837f8674
bearer_token = ZXlKMGVYQWlPaUpLVjFRaUxDSmhiR2NpT2lKSVV6STFOaUo5LmV5SnpaWE56YVc5dVZHOXJaVzRpT2lJd09Ea3dPV1kwWVRrMFltTmtPR1kzWlRrek0yVTNNell4TVRFMk5qRTVOekpsT0RRMU5qTm1OekJtWlRBeVptUmlOR0V6TURjM01XWm1OemszWWpCa0lpd2ljMlZ6YzJsdmJrbGtJam9pTldVeE5tWmhNakJrTXpRM1lqazNNR1F5TnpFMU1HTTBOelE0TnpSaE1ERXpOekkzT1dZM01UQmxaV001T0dWaU1XRmxNamN6Wm1VeE1tWXdaR1l3TkNJc0ltNWhiV1Z6Y0dGalpTSTZJalkyTkRsaE1qVmhNRFl6TXpkbE5URmhPRGRpTnpkaE4yUTRNMlUxT0dZMU1qSTNPVFUwTlRJME5UWTJORGxpT0dVd01UazFOelE0TXpkbU9EWTNOQ0lzSW1WNGNDSTZNak00TkRVMk9Ua3pPQ3dpWTNWemRHOXRVR0Y1Ykc5aFpDSTZleUoxYzJWeVZHbHdJam9pWlRGa05XRm1OakJpWkdJM01UQmxaRFkyWVRaaE1HTXpPREF4WTJKa05ERXhabU5pTURJNE9UQmlNR1kwTjJJMk9HUXhORGd3WW1ZM1pHWTFabVE1T0NKOWZRLm5Jb05FOXd5d21mQ01rT1dpQ0FDRlVWSUFrUFhBMzg1TjlhNEtGWnVfMHc=

[processing]
too_many_requests_sleep_time = 60
attachment_pause = 2
max_api_retries = 5
api_backoff_factor = 2
api_max_backoff = 60
api_timeout = 30

[input]
csv_check_interval_seconds = 86400
csv_filename_pattern = *.csv # amend to exported-file-*.csv
import_batch_size = 100

[retry]
max_retry_attempts = 3
retry_backoff_multiplier = 2
idle_sleep_seconds = 60
active_sleep_seconds = 5
tips_per_batch = 10

[circuit_breaker]
failure_threshold_percent = 50
recovery_threshold_percent = 10
circuit_open_duration_seconds = 300
sample_size = 10

[logging]
log_level = INFO
extended_debug_mode = false
log_retention_days = 30
compress_old_logs = true
log_filename_pattern = {script_name}_{date}.log

[continuous]
cycle_sleep_seconds = 300
import_csv_every_n_cycles = 3
resolve_hashes_every_n_cycles = 10
sftp_download_every_n_cycles = 6

[sftp]
enabled = true
host = ssh.noggin-sftp.goldstartransport.com.au
port = 18765
username = u824-zdigcggtoza6
private_key_path = /home/noggin_admin/scripts/.ssh/noggin/noggin-openssh.pem
host_key_fingerprint = ssh-ed25519 255 Tc8ZNyPlk1EGa6u/DPp7UsJR1lhaw4rxb8IP1IWOCVM
remote_path = /home/customer/sftp/tip
file_pattern = *.csv # exported-file-*.csv
config_file = config/sftp_config.ini

[csv_import]
batch_size = 100 # default batch size = 100. higher values more efficient, but more memory
config_dir = config
